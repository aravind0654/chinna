{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Crypto_Price_Prtediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aravind0654/chinna/blob/master/Crypto_Price_Prtediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr7RpAXRLmwL"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-qd1LVvcq1f"
      },
      "source": [
        "import math\n",
        "import pandas_datareader as web\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Dense, LSTM\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import GRU,Dropout\n",
        "from keras.optimizers import SGD\n",
        "plt.style.use('fivethirtyeight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWbchTqGMAP-"
      },
      "source": [
        "Retrieving data from web using source_id Yahoo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h6nZaL7eikg"
      },
      "source": [
        "df = web.DataReader('XRP-INR',data_source =\"yahoo\",start = '2014-04-01', end = '2021-01-05')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "kKRvKI6leiul",
        "outputId": "17c8c080-4ff1-4bb7-db61-a170c12f7be9"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-09-16</th>\n",
              "      <td>0.353866</td>\n",
              "      <td>0.312755</td>\n",
              "      <td>0.312755</td>\n",
              "      <td>0.328770</td>\n",
              "      <td>78071364</td>\n",
              "      <td>0.328770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-17</th>\n",
              "      <td>0.337389</td>\n",
              "      <td>0.309153</td>\n",
              "      <td>0.328747</td>\n",
              "      <td>0.311850</td>\n",
              "      <td>29824901</td>\n",
              "      <td>0.311850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-18</th>\n",
              "      <td>0.313793</td>\n",
              "      <td>0.296433</td>\n",
              "      <td>0.311754</td>\n",
              "      <td>0.300736</td>\n",
              "      <td>24772582</td>\n",
              "      <td>0.300736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-19</th>\n",
              "      <td>0.301444</td>\n",
              "      <td>0.288179</td>\n",
              "      <td>0.300708</td>\n",
              "      <td>0.290355</td>\n",
              "      <td>19631487</td>\n",
              "      <td>0.290355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-20</th>\n",
              "      <td>0.291548</td>\n",
              "      <td>0.276258</td>\n",
              "      <td>0.290149</td>\n",
              "      <td>0.278078</td>\n",
              "      <td>18837395</td>\n",
              "      <td>0.278078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-16</th>\n",
              "      <td>17.826361</td>\n",
              "      <td>17.569239</td>\n",
              "      <td>17.666395</td>\n",
              "      <td>17.695030</td>\n",
              "      <td>86187567611</td>\n",
              "      <td>17.695030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-17</th>\n",
              "      <td>17.877811</td>\n",
              "      <td>17.668648</td>\n",
              "      <td>17.689140</td>\n",
              "      <td>17.789953</td>\n",
              "      <td>90976678694</td>\n",
              "      <td>17.789953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-18</th>\n",
              "      <td>18.300880</td>\n",
              "      <td>17.652044</td>\n",
              "      <td>17.796110</td>\n",
              "      <td>18.053129</td>\n",
              "      <td>105376544733</td>\n",
              "      <td>18.053129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-19</th>\n",
              "      <td>18.292725</td>\n",
              "      <td>17.823393</td>\n",
              "      <td>18.050407</td>\n",
              "      <td>17.897989</td>\n",
              "      <td>112159734744</td>\n",
              "      <td>17.897989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-20</th>\n",
              "      <td>18.797001</td>\n",
              "      <td>17.873928</td>\n",
              "      <td>17.891514</td>\n",
              "      <td>18.550510</td>\n",
              "      <td>170041151424</td>\n",
              "      <td>18.550510</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2227 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 High        Low       Open      Close        Volume  Adj Close\n",
              "Date                                                                           \n",
              "2014-09-16   0.353866   0.312755   0.312755   0.328770      78071364   0.328770\n",
              "2014-09-17   0.337389   0.309153   0.328747   0.311850      29824901   0.311850\n",
              "2014-09-18   0.313793   0.296433   0.311754   0.300736      24772582   0.300736\n",
              "2014-09-19   0.301444   0.288179   0.300708   0.290355      19631487   0.290355\n",
              "2014-09-20   0.291548   0.276258   0.290149   0.278078      18837395   0.278078\n",
              "...               ...        ...        ...        ...           ...        ...\n",
              "2020-10-16  17.826361  17.569239  17.666395  17.695030   86187567611  17.695030\n",
              "2020-10-17  17.877811  17.668648  17.689140  17.789953   90976678694  17.789953\n",
              "2020-10-18  18.300880  17.652044  17.796110  18.053129  105376544733  18.053129\n",
              "2020-10-19  18.292725  17.823393  18.050407  17.897989  112159734744  17.897989\n",
              "2020-10-20  18.797001  17.873928  17.891514  18.550510  170041151424  18.550510\n",
              "\n",
              "[2227 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zooepBT6eixT",
        "outputId": "97fd9b3f-349c-4fd0-d011-710577210a96"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2227, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy7nZqGDMkPO"
      },
      "source": [
        "* Creating a graph to visualize the data.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "CFCtju39eizl",
        "outputId": "92e3bf86-5ade-43b3-b3f6-3244a4f8545f"
      },
      "source": [
        "plt.figure(figsize=(16,8))\n",
        "plt.title('closingprice')\n",
        "plt.plot(df['Close'])\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('closingprice')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wINz7DF4NQiy"
      },
      "source": [
        "Training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQAgLj5bQlBo"
      },
      "source": [
        "Creating a new data frame with only the closing price and convert it to an array.\n",
        "Then created training data set to contain about 80% of the data a variable using the length of the training data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9J_w90kUei29",
        "outputId": "5a032399-5740-47e7-ad06-49984ba9fedc"
      },
      "source": [
        "data = df.filter(['Close'])\n",
        "dataset = data.values\n",
        "training_data_len = math.ceil(len(dataset)*.8)\n",
        "training_data_len"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1782"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o7ppGgdQosy"
      },
      "source": [
        "scaling the data set to be values between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWpEpvn7kw4p",
        "outputId": "de514a64-9034-4453-c74e-fef1c5a3a36e"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaler_data = scaler.fit_transform(dataset)\n",
        "scaler_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00026657],\n",
              "       [0.00018738],\n",
              "       [0.00013536],\n",
              "       ...,\n",
              "       [0.08322835],\n",
              "       [0.08250219],\n",
              "       [0.08555643]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEEYCWyGQznr"
      },
      "source": [
        "Create a training data set that contains the past 60 day closing price values that we want to use to predict the 61st closing price value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtgwIm9Kkw7E",
        "outputId": "fa2bf60b-f41c-49c0-feb8-df1aa8aa0b1f"
      },
      "source": [
        "train_data = scaler_data[0:training_data_len]\n",
        "X_train=[]\n",
        "Y_train=[]\n",
        "for i in range (60,len(train_data)):\n",
        "  X_train.append(train_data[i-60:i,0])\n",
        "  Y_train.append(train_data[i,0])\n",
        "  if i <=60:\n",
        "    print(X_train)\n",
        "    print(Y_train)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([2.66573196e-04, 1.87377888e-04, 1.35355722e-04, 8.67655445e-05,\n",
            "       2.93007157e-05, 5.59349908e-05, 4.57331877e-05, 5.88809787e-05,\n",
            "       8.33137489e-05, 4.85792974e-05, 7.41804750e-05, 2.39281064e-04,\n",
            "       8.29556661e-05, 7.37672918e-05, 1.00410216e-04, 1.31570116e-04,\n",
            "       1.74407952e-04, 1.50982892e-04, 1.06964094e-04, 9.00513414e-05,\n",
            "       9.47884409e-05, 1.02228808e-04, 1.05908956e-04, 1.24767240e-04,\n",
            "       9.08120058e-05, 1.20806708e-04, 9.35843229e-05, 1.27412338e-04,\n",
            "       1.14301932e-04, 1.30177541e-04, 1.35955689e-04, 1.53472314e-04,\n",
            "       1.48900655e-04, 1.81524552e-04, 2.13598282e-04, 2.13289999e-04,\n",
            "       1.99651884e-04, 1.82461538e-04, 7.86888032e-05, 2.96308996e-05,\n",
            "       1.30946575e-04, 1.14881811e-04, 9.75083079e-05, 1.33626268e-04,\n",
            "       1.26135683e-04, 6.98646494e-05, 6.80142526e-05, 1.10353814e-04,\n",
            "       1.05999069e-04, 1.25197581e-04, 1.31510412e-04, 1.31755086e-04,\n",
            "       1.40357025e-04, 1.45861345e-04, 1.37964970e-04, 1.37941675e-04,\n",
            "       1.91713382e-04, 1.79235305e-04, 2.28613209e-04, 1.86968192e-04])]\n",
            "[0.00022412789776498666]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJmEL7QlRCds"
      },
      "source": [
        "converting the independent train data set â€˜x_trainâ€™ and dependent train data set â€˜y_trainâ€™ to numpy arrays so they can be used for training the LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9uth51nnjN9"
      },
      "source": [
        "x_train,y_train = np.array(X_train),np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYic76T4LllZ"
      },
      "source": [
        "Reshape the data to be 3-dimensional in the form [number of samples, number of time steps, and number of features]. The LSTM model is expecting a 3-dimensional data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayOtLkaSnjQu",
        "outputId": "cf3bd28b-baba-41c9-bce2-51b86f3df353"
      },
      "source": [
        "x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],1))\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1722, 60, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojG0f9OrRRnJ"
      },
      "source": [
        "Build the LSTM model to have two LSTM layers with 50 neurons and two Dense layers, one with 25 neurons and the other with 1 neuron."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFGAGiKRnjTi"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape = (x_train.shape[1],1)))\n",
        "model.add(LSTM(50,return_sequences=False))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk-4Zv_cRanf"
      },
      "source": [
        "Compile the model using the mean squared error (MSE) loss function and the adam optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiT9dyWInjWV"
      },
      "source": [
        "model.compile(optimizer= 'adam',loss = 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUES47voRlFV"
      },
      "source": [
        "Train the model using the training data sets. Note, fit is another name for train. Batch size is the total number of training examples present in a single batch, and epoch is the number of iterations when an entire data set is passed forward and backward through the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QMv9Ek0njZe",
        "outputId": "1f191606-8be2-43b2-cf39-e5a5b37d1b57"
      },
      "source": [
        "model.fit(x_train,y_train,batch_size= 43,epochs=1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "41/41 [==============================] - 9s 9ms/step - loss: 0.0061\n",
            "Epoch 2/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 3/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 8.5307e-04\n",
            "Epoch 4/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 8.6989e-04\n",
            "Epoch 5/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 5.4809e-04\n",
            "Epoch 6/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 4.1806e-04\n",
            "Epoch 7/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 4.4550e-04\n",
            "Epoch 8/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 7.0077e-04\n",
            "Epoch 9/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 4.1443e-04\n",
            "Epoch 10/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.0495e-04\n",
            "Epoch 11/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.6284e-04\n",
            "Epoch 12/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 5.7870e-04\n",
            "Epoch 13/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.4562e-04\n",
            "Epoch 14/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 6.3798e-04\n",
            "Epoch 15/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 4.6334e-04\n",
            "Epoch 16/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.5339e-04\n",
            "Epoch 17/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.3962e-04\n",
            "Epoch 18/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.7458e-04\n",
            "Epoch 19/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 5.1630e-04\n",
            "Epoch 20/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 5.1597e-04\n",
            "Epoch 21/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 3.3990e-04\n",
            "Epoch 22/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.1238e-04\n",
            "Epoch 23/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 5.1010e-04\n",
            "Epoch 24/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.5077e-04\n",
            "Epoch 25/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.4094e-04\n",
            "Epoch 26/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.7086e-04\n",
            "Epoch 27/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.5561e-04\n",
            "Epoch 28/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 5.7871e-04\n",
            "Epoch 29/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.9520e-04\n",
            "Epoch 30/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.4385e-04\n",
            "Epoch 31/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.6471e-04\n",
            "Epoch 32/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 3.7069e-04\n",
            "Epoch 33/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.4595e-04\n",
            "Epoch 34/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 3.6683e-04\n",
            "Epoch 35/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.6285e-04\n",
            "Epoch 36/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0441e-04\n",
            "Epoch 37/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 4.6192e-04\n",
            "Epoch 38/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.6670e-04\n",
            "Epoch 39/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.5980e-04\n",
            "Epoch 40/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.8956e-04\n",
            "Epoch 41/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.6343e-04\n",
            "Epoch 42/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.3906e-04\n",
            "Epoch 43/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.3832e-04\n",
            "Epoch 44/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.6368e-04\n",
            "Epoch 45/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 3.6372e-04\n",
            "Epoch 46/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 4.0624e-04\n",
            "Epoch 47/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.4271e-04\n",
            "Epoch 48/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 4.4085e-04\n",
            "Epoch 49/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.3765e-04\n",
            "Epoch 50/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.3941e-04\n",
            "Epoch 51/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.9912e-04\n",
            "Epoch 52/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.7235e-04\n",
            "Epoch 53/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6555e-04\n",
            "Epoch 54/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.6926e-04\n",
            "Epoch 55/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.7953e-04\n",
            "Epoch 56/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 4.1560e-04\n",
            "Epoch 57/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.9308e-04\n",
            "Epoch 58/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.5630e-04\n",
            "Epoch 59/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.1329e-04\n",
            "Epoch 60/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0720e-04\n",
            "Epoch 61/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.6953e-04\n",
            "Epoch 62/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.5904e-04\n",
            "Epoch 63/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.6379e-04\n",
            "Epoch 64/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.3312e-04\n",
            "Epoch 65/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 3.3667e-04\n",
            "Epoch 66/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7037e-04\n",
            "Epoch 67/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.5945e-04\n",
            "Epoch 68/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2941e-04\n",
            "Epoch 69/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.0620e-04\n",
            "Epoch 70/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.9798e-04\n",
            "Epoch 71/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.9916e-04\n",
            "Epoch 72/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.1086e-04\n",
            "Epoch 73/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.8339e-04\n",
            "Epoch 74/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3641e-04\n",
            "Epoch 75/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5431e-04\n",
            "Epoch 76/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.9781e-04\n",
            "Epoch 77/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.9250e-04\n",
            "Epoch 78/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.2451e-04\n",
            "Epoch 79/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3481e-04\n",
            "Epoch 80/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2144e-04\n",
            "Epoch 81/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6751e-04\n",
            "Epoch 82/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.9416e-04\n",
            "Epoch 83/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0789e-04\n",
            "Epoch 84/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8069e-04\n",
            "Epoch 85/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.1755e-04\n",
            "Epoch 86/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.9333e-04\n",
            "Epoch 87/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 4.3561e-04\n",
            "Epoch 88/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7236e-04\n",
            "Epoch 89/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.7952e-04\n",
            "Epoch 90/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.6692e-04\n",
            "Epoch 91/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.2443e-04\n",
            "Epoch 92/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5871e-04\n",
            "Epoch 93/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8920e-04\n",
            "Epoch 94/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0458e-04\n",
            "Epoch 95/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.4160e-04\n",
            "Epoch 96/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.7171e-04\n",
            "Epoch 97/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0215e-04\n",
            "Epoch 98/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7741e-04\n",
            "Epoch 99/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7093e-04\n",
            "Epoch 100/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0624e-04\n",
            "Epoch 101/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.3695e-04\n",
            "Epoch 102/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2284e-04\n",
            "Epoch 103/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.8168e-04\n",
            "Epoch 104/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.0079e-04\n",
            "Epoch 105/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5075e-04\n",
            "Epoch 106/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5613e-04\n",
            "Epoch 107/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.6771e-04\n",
            "Epoch 108/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.4942e-04\n",
            "Epoch 109/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.8632e-04\n",
            "Epoch 110/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.1318e-04\n",
            "Epoch 111/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9300e-04\n",
            "Epoch 112/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.3050e-04\n",
            "Epoch 113/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.8644e-04\n",
            "Epoch 114/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.2503e-04\n",
            "Epoch 115/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0477e-04\n",
            "Epoch 116/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.1398e-04\n",
            "Epoch 117/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.9489e-04\n",
            "Epoch 118/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3145e-04\n",
            "Epoch 119/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5871e-04\n",
            "Epoch 120/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.6038e-04\n",
            "Epoch 121/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.0952e-04\n",
            "Epoch 122/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.3513e-04\n",
            "Epoch 123/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8706e-04\n",
            "Epoch 124/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0513e-04\n",
            "Epoch 125/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4836e-04\n",
            "Epoch 126/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2553e-04\n",
            "Epoch 127/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5703e-04\n",
            "Epoch 128/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2956e-04\n",
            "Epoch 129/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3861e-04\n",
            "Epoch 130/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.2122e-04\n",
            "Epoch 131/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.3953e-04\n",
            "Epoch 132/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.9232e-04\n",
            "Epoch 133/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.8994e-04\n",
            "Epoch 134/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6266e-04\n",
            "Epoch 135/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.8946e-04\n",
            "Epoch 136/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7863e-04\n",
            "Epoch 137/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6858e-04\n",
            "Epoch 138/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2681e-04\n",
            "Epoch 139/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.8337e-04\n",
            "Epoch 140/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.5293e-04\n",
            "Epoch 141/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.3492e-04\n",
            "Epoch 142/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.1878e-04\n",
            "Epoch 143/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.1374e-04\n",
            "Epoch 144/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7683e-04\n",
            "Epoch 145/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.0335e-04\n",
            "Epoch 146/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.9538e-04\n",
            "Epoch 147/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7162e-04\n",
            "Epoch 148/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.1401e-04\n",
            "Epoch 149/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7929e-04\n",
            "Epoch 150/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7329e-04\n",
            "Epoch 151/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7822e-04\n",
            "Epoch 152/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7546e-04\n",
            "Epoch 153/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 8.6729e-05\n",
            "Epoch 154/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.7717e-04\n",
            "Epoch 155/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3922e-04\n",
            "Epoch 156/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4729e-04\n",
            "Epoch 157/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.4463e-04\n",
            "Epoch 158/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7732e-04\n",
            "Epoch 159/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6408e-04\n",
            "Epoch 160/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6720e-04\n",
            "Epoch 161/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2517e-04\n",
            "Epoch 162/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3413e-04\n",
            "Epoch 163/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5757e-04\n",
            "Epoch 164/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2140e-04\n",
            "Epoch 165/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.0548e-04\n",
            "Epoch 166/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2673e-04\n",
            "Epoch 167/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.1745e-04\n",
            "Epoch 168/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6684e-04\n",
            "Epoch 169/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2713e-04\n",
            "Epoch 170/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7855e-04\n",
            "Epoch 171/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2232e-04\n",
            "Epoch 172/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2931e-04\n",
            "Epoch 173/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 8.7818e-05\n",
            "Epoch 174/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3401e-04\n",
            "Epoch 175/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.7191e-04\n",
            "Epoch 176/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4873e-04\n",
            "Epoch 177/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8302e-04\n",
            "Epoch 178/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2743e-04\n",
            "Epoch 179/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4865e-04\n",
            "Epoch 180/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 3.0658e-04\n",
            "Epoch 181/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5422e-04\n",
            "Epoch 182/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.6505e-04\n",
            "Epoch 183/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.8610e-04\n",
            "Epoch 184/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7580e-04\n",
            "Epoch 185/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.4697e-04\n",
            "Epoch 186/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8543e-04\n",
            "Epoch 187/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.6496e-04\n",
            "Epoch 188/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.5388e-04\n",
            "Epoch 189/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6114e-04\n",
            "Epoch 190/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4727e-04\n",
            "Epoch 191/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2697e-04\n",
            "Epoch 192/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3063e-04\n",
            "Epoch 193/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.2208e-04\n",
            "Epoch 194/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6351e-04\n",
            "Epoch 195/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3356e-04\n",
            "Epoch 196/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2483e-04\n",
            "Epoch 197/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6746e-04\n",
            "Epoch 198/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4534e-04\n",
            "Epoch 199/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6025e-04\n",
            "Epoch 200/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.6963e-04\n",
            "Epoch 201/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5289e-04\n",
            "Epoch 202/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8988e-04\n",
            "Epoch 203/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.7686e-04\n",
            "Epoch 204/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5187e-04\n",
            "Epoch 205/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1576e-04\n",
            "Epoch 206/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.9052e-04\n",
            "Epoch 207/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.2558e-04\n",
            "Epoch 208/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.4182e-04\n",
            "Epoch 209/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3485e-04\n",
            "Epoch 210/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3771e-04\n",
            "Epoch 211/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1810e-04\n",
            "Epoch 212/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6488e-04\n",
            "Epoch 213/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4712e-04\n",
            "Epoch 214/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3650e-04\n",
            "Epoch 215/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1210e-04\n",
            "Epoch 216/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3861e-04\n",
            "Epoch 217/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.8545e-04\n",
            "Epoch 218/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4426e-04\n",
            "Epoch 219/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7696e-04\n",
            "Epoch 220/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2034e-04\n",
            "Epoch 221/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.8904e-04\n",
            "Epoch 222/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0292e-04\n",
            "Epoch 223/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4719e-04\n",
            "Epoch 224/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5696e-04\n",
            "Epoch 225/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.4346e-04\n",
            "Epoch 226/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3189e-04\n",
            "Epoch 227/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5756e-04\n",
            "Epoch 228/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.4833e-04\n",
            "Epoch 229/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 2.0926e-04\n",
            "Epoch 230/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2331e-04\n",
            "Epoch 231/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0993e-04\n",
            "Epoch 232/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.4333e-04\n",
            "Epoch 233/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5846e-04\n",
            "Epoch 234/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.7029e-04\n",
            "Epoch 235/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0847e-04\n",
            "Epoch 236/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1429e-04\n",
            "Epoch 237/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.3212e-04\n",
            "Epoch 238/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0605e-04\n",
            "Epoch 239/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 4.0845e-04\n",
            "Epoch 240/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.3267e-04\n",
            "Epoch 241/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2834e-04\n",
            "Epoch 242/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.3042e-04\n",
            "Epoch 243/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.1906e-04\n",
            "Epoch 244/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2073e-04\n",
            "Epoch 245/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6675e-04\n",
            "Epoch 246/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3850e-04\n",
            "Epoch 247/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5761e-04\n",
            "Epoch 248/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.5960e-05\n",
            "Epoch 249/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2425e-04\n",
            "Epoch 250/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4792e-04\n",
            "Epoch 251/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6956e-04\n",
            "Epoch 252/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 3.0592e-04\n",
            "Epoch 253/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4043e-04\n",
            "Epoch 254/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.6301e-04\n",
            "Epoch 255/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 7.8672e-05\n",
            "Epoch 256/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0729e-04\n",
            "Epoch 257/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5447e-04\n",
            "Epoch 258/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3612e-04\n",
            "Epoch 259/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4067e-04\n",
            "Epoch 260/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0091e-04\n",
            "Epoch 261/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3983e-04\n",
            "Epoch 262/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0133e-04\n",
            "Epoch 263/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4770e-04\n",
            "Epoch 264/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1531e-04\n",
            "Epoch 265/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0997e-04\n",
            "Epoch 266/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3482e-04\n",
            "Epoch 267/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.9687e-05\n",
            "Epoch 268/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 2.0288e-04\n",
            "Epoch 269/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6941e-04\n",
            "Epoch 270/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0282e-04\n",
            "Epoch 271/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.4089e-05\n",
            "Epoch 272/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2026e-04\n",
            "Epoch 273/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3945e-04\n",
            "Epoch 274/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1538e-04\n",
            "Epoch 275/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2061e-04\n",
            "Epoch 276/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7562e-04\n",
            "Epoch 277/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4482e-04\n",
            "Epoch 278/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2707e-04\n",
            "Epoch 279/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.4126e-05\n",
            "Epoch 280/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6218e-04\n",
            "Epoch 281/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3308e-04\n",
            "Epoch 282/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1992e-04\n",
            "Epoch 283/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2085e-04\n",
            "Epoch 284/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0068e-04\n",
            "Epoch 285/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.5402e-04\n",
            "Epoch 286/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2800e-04\n",
            "Epoch 287/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0732e-04\n",
            "Epoch 288/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 8.7540e-05\n",
            "Epoch 289/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5594e-04\n",
            "Epoch 290/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.4284e-04\n",
            "Epoch 291/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4844e-04\n",
            "Epoch 292/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5257e-04\n",
            "Epoch 293/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3081e-04\n",
            "Epoch 294/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2926e-04\n",
            "Epoch 295/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5409e-04\n",
            "Epoch 296/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2300e-04\n",
            "Epoch 297/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3520e-04\n",
            "Epoch 298/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 7.5788e-05\n",
            "Epoch 299/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6626e-04\n",
            "Epoch 300/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0792e-04\n",
            "Epoch 301/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2717e-04\n",
            "Epoch 302/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1742e-04\n",
            "Epoch 303/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5226e-04\n",
            "Epoch 304/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5198e-04\n",
            "Epoch 305/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.7513e-05\n",
            "Epoch 306/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3354e-04\n",
            "Epoch 307/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5379e-04\n",
            "Epoch 308/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2506e-04\n",
            "Epoch 309/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0166e-04\n",
            "Epoch 310/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0017e-04\n",
            "Epoch 311/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3802e-04\n",
            "Epoch 312/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.7195e-04\n",
            "Epoch 313/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.7133e-05\n",
            "Epoch 314/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2629e-04\n",
            "Epoch 315/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2336e-04\n",
            "Epoch 316/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1679e-04\n",
            "Epoch 317/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0533e-04\n",
            "Epoch 318/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.9320e-05\n",
            "Epoch 319/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1263e-04\n",
            "Epoch 320/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0185e-04\n",
            "Epoch 321/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5497e-04\n",
            "Epoch 322/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.6998e-04\n",
            "Epoch 323/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.0578e-05\n",
            "Epoch 324/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0764e-04\n",
            "Epoch 325/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 8.2333e-05\n",
            "Epoch 326/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.8844e-05\n",
            "Epoch 327/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3285e-04\n",
            "Epoch 328/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 2.6955e-04\n",
            "Epoch 329/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 8.5061e-05\n",
            "Epoch 330/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1908e-04\n",
            "Epoch 331/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2841e-04\n",
            "Epoch 332/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.6033e-04\n",
            "Epoch 333/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.5037e-04\n",
            "Epoch 334/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0889e-04\n",
            "Epoch 335/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2840e-04\n",
            "Epoch 336/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1636e-04\n",
            "Epoch 337/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1137e-04\n",
            "Epoch 338/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0159e-04\n",
            "Epoch 339/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 8.6388e-05\n",
            "Epoch 340/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0961e-04\n",
            "Epoch 341/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0296e-04\n",
            "Epoch 342/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.8657e-04\n",
            "Epoch 343/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1752e-04\n",
            "Epoch 344/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.7794e-04\n",
            "Epoch 345/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0681e-04\n",
            "Epoch 346/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1519e-04\n",
            "Epoch 347/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2848e-04\n",
            "Epoch 348/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 8.7053e-05\n",
            "Epoch 349/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0600e-04\n",
            "Epoch 350/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.5437e-04\n",
            "Epoch 351/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.1045e-04\n",
            "Epoch 352/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.4547e-04\n",
            "Epoch 353/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3767e-04\n",
            "Epoch 354/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2343e-04\n",
            "Epoch 355/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 9.6426e-05\n",
            "Epoch 356/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0478e-04\n",
            "Epoch 357/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.3354e-04\n",
            "Epoch 358/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.5390e-05\n",
            "Epoch 359/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.5610e-04\n",
            "Epoch 360/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2310e-04\n",
            "Epoch 361/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0255e-04\n",
            "Epoch 362/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0011e-04\n",
            "Epoch 363/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 6.7553e-05\n",
            "Epoch 364/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2426e-04\n",
            "Epoch 365/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0248e-04\n",
            "Epoch 366/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.0299e-04\n",
            "Epoch 367/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0296e-04\n",
            "Epoch 368/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1829e-04\n",
            "Epoch 369/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.1232e-04\n",
            "Epoch 370/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4474e-04\n",
            "Epoch 371/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2943e-04\n",
            "Epoch 372/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.3165e-05\n",
            "Epoch 373/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0864e-04\n",
            "Epoch 374/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.0551e-05\n",
            "Epoch 375/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3487e-04\n",
            "Epoch 376/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.2300e-04\n",
            "Epoch 377/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 8.1055e-05\n",
            "Epoch 378/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.1177e-04\n",
            "Epoch 379/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2866e-04\n",
            "Epoch 380/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 8.9865e-05\n",
            "Epoch 381/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.4554e-04\n",
            "Epoch 382/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0983e-04\n",
            "Epoch 383/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 8.2273e-05\n",
            "Epoch 384/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3017e-04\n",
            "Epoch 385/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.2095e-04\n",
            "Epoch 386/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.4094e-04\n",
            "Epoch 387/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0033e-04\n",
            "Epoch 388/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.9821e-04\n",
            "Epoch 389/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.0289e-04\n",
            "Epoch 390/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.2981e-05\n",
            "Epoch 391/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.2639e-05\n",
            "Epoch 392/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0259e-04\n",
            "Epoch 393/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.7835e-04\n",
            "Epoch 394/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 9.1925e-05\n",
            "Epoch 395/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.0346e-04\n",
            "Epoch 396/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 9.9180e-05\n",
            "Epoch 397/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 1.2376e-04\n",
            "Epoch 398/1000\n",
            "41/41 [==============================] - 0s 7ms/step - loss: 1.3044e-04\n",
            "Epoch 399/1000\n",
            "41/41 [==============================] - 0s 8ms/step - loss: 7.2109e-05\n",
            "Epoch 400/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 1.5369e-04\n",
            "Epoch 401/1000\n",
            "41/41 [==============================] - 0s 9ms/step - loss: 8.2134e-05\n",
            "Epoch 402/1000\n",
            " 1/41 [..............................] - ETA: 0s - loss: 1.2126e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e38c877ca82c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m43\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC4miRx-RuRW"
      },
      "source": [
        "Create a test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uLC2v0qTnjmc"
      },
      "source": [
        "test_data = scaler_data[training_data_len-60:,:]\n",
        "x_test = []\n",
        "y_test = dataset[training_data_len:,:]\n",
        "for i in range(60,len(test_data)):\n",
        "  x_test.append(test_data[i-60:i,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrddFF5iR8am"
      },
      "source": [
        "Then convert the independent test data set â€˜x_testâ€™ to a numpy array so it can be used for testing the LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ec9frRx_njpm"
      },
      "source": [
        "x_test = np.array(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EUv30fvvroVV"
      },
      "source": [
        "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8nDlllRprpEZ"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "siZ9G3klrpHB"
      },
      "source": [
        "predictions = scaler.inverse_transform(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ru5S7HxrpJZ"
      },
      "source": [
        "#calculating root mean_square_error\n",
        "rmse = np.sqrt(np.mean(predictions - y_test)**2)\n",
        "rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73dYQAuSovn"
      },
      "source": [
        "visualizing the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JNkh7nd0roX6"
      },
      "source": [
        "train = data[:training_data_len]\n",
        "valid = data[training_data_len:]\n",
        "valid['predictions'] = predictions\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('model')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('closingprice')\n",
        "plt.plot(train['Close'])\n",
        "plt.plot(valid[['Close','predictions']])\n",
        "plt.legend(['Train','val','predictions'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8dO_iNnScW2"
      },
      "source": [
        "Actual and predicted values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1iMBADBRtaIv"
      },
      "source": [
        "valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uob7XPseSWf-"
      },
      "source": [
        "Testing the model with new data using last_60_days as test data to predict price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7ECsKGdStaLy"
      },
      "source": [
        "df = web.DataReader('BTC-USD',data_source =\"yahoo\",start = '2014-04-01', end = '2020-11-24')\n",
        "#Create a new dataframe\n",
        "new_df = df.filter(['Close'])\n",
        "#Get teh last 60 day closing price \n",
        "last_60_days = new_df[-60:].values\n",
        "#Scale the data to be values between 0 and 1\n",
        "last_60_days_scaled = scaler.transform(last_60_days)\n",
        "#Create an empty list\n",
        "X_test = []\n",
        "#Append teh past 60 days\n",
        "X_test.append(last_60_days_scaled)\n",
        "#Convert the X_test data set to a numpy array\n",
        "X_test = np.array(X_test)\n",
        "#Reshape the data\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "#Get the predicted scaled price\n",
        "pred_price = model.predict(X_test)\n",
        "#undo the scaling \n",
        "pred_price = scaler.inverse_transform(pred_price)\n",
        "print(pred_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gQIqSNUdPnK"
      },
      "source": [
        "Actual price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_m7VjNxktaOY"
      },
      "source": [
        "df = web.DataReader('BTC-USD',data_source =\"yahoo\",start = '2020-11-25', end = '2020-11-25')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gjVzn1s7taRI"
      },
      "source": [
        "print(df['Close'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx6q5h3jdbKn"
      },
      "source": [
        "Building GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yi3Z4YYJtaV8"
      },
      "source": [
        "# The GRU architecture\n",
        "regressorGRU = Sequential()\n",
        "# First GRU layer with Dropout regularisation\n",
        "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(x_train.shape[1],1), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Second GRU layer\n",
        "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(x_train.shape[1],1), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Third GRU layer\n",
        "regressorGRU.add(GRU(units=50, return_sequences=True, input_shape=(x_train.shape[1],1), activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# Fourth GRU layer\n",
        "regressorGRU.add(GRU(units=50, activation='tanh'))\n",
        "regressorGRU.add(Dropout(0.2))\n",
        "# The output layer\n",
        "regressorGRU.add(Dense(units=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fRSFb1x6taZT"
      },
      "source": [
        "#compiling the model\n",
        "regressorGRU.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KWttmBvMTndU"
      },
      "source": [
        "#fitting the model\n",
        "regressorGRU.fit(x_train,y_train,batch_size= 20,epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Si7lesiCTnjK"
      },
      "source": [
        "#converting and scaling test_data\n",
        "x_test = np.array(x_test)\n",
        "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],1))\n",
        "predicted_with_gru = regressorGRU.predict(x_test)\n",
        "predicted_with_gru = scaler.inverse_transform(predicted_with_gru)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VV8Fve7ETr5Z"
      },
      "source": [
        "#Rmse Error\n",
        "rmse = np.sqrt(np.mean(predicted_with_gru - y_test)**2)\n",
        "rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umkKrGBphKtT"
      },
      "source": [
        "visualising the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "omSWwzogTr8U"
      },
      "source": [
        "train = data[:training_data_len]\n",
        "valid = data[training_data_len:]\n",
        "valid['predicted_with_gru'] = predicted_with_gru\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('model')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('closingprice')\n",
        "plt.plot(train['Close'])\n",
        "plt.plot(valid[['Close','predicted_with_gru']])\n",
        "plt.legend(['Train','val','predicted_with_gru'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-kxuJX9hSc4"
      },
      "source": [
        "Actual and predicted prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FODC0y4jTr_G"
      },
      "source": [
        "valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOT46v8ohlkj"
      },
      "source": [
        "Testing the model with new data with last_60days as test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nFXoRo_ZTsCO"
      },
      "source": [
        "\n",
        "df = web.DataReader('XRP-INR',data_source =\"yahoo\",start = '2014-04-01', end = '2020-11-24')\n",
        "#Create a new dataframe\n",
        "new_df = df.filter(['Close'])\n",
        "#Get teh last 60 day closing price \n",
        "last_60_days = new_df[-60:].values\n",
        "#Scale the data to be values between 0 and 1\n",
        "last_60_days_scaled = scaler.transform(last_60_days)\n",
        "#Create an empty list\n",
        "X_test = []\n",
        "#Append teh past 60 days\n",
        "X_test.append(last_60_days_scaled)\n",
        "#Convert the X_test data set to a numpy array\n",
        "X_test = np.array(X_test)\n",
        "#Reshape the data\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "#Get the predicted scaled price\n",
        "pred_price =regressorGRU .predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8docXrBciFl8"
      },
      "source": [
        "#undo the scaling and predicting price\n",
        "pred_price = scaler.inverse_transform(pred_price)\n",
        "print(pred_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZQSHVgOBUB6g"
      },
      "source": [
        "#Actual price\n",
        "df = web.DataReader('XRP-INR',data_source =\"yahoo\",start = '2020-11-25', end = '2020-11-25')\n",
        "print(df['Close'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}